import 'dart:io';
import 'dart:async';
import 'dart:convert';
import 'dart:typed_data';
import 'package:flutter/foundation.dart';
import 'package:flutter_sound/flutter_sound.dart';
import 'package:permission_handler/permission_handler.dart';
import 'package:http/http.dart' as http;

class AudioService extends ChangeNotifier {
  FlutterSoundRecorder? _recorder;
  FlutterSoundPlayer? _player;
  bool _isRecording = false;
  bool _isPlaying = false;

  bool get isRecording => _isRecording;
  bool get isPlaying => _isPlaying;

  Function(String)? onAudioData;

  AudioService() {
    _initializeAudio();
  }

  Future<void> _initializeAudio() async {
    _recorder = FlutterSoundRecorder();
    _player = FlutterSoundPlayer();

    await Permission.microphone.request();

    await _recorder!.openRecorder();
    await _player!.openPlayer();
  }

  Future<void> startRecording() async {
    if (_recorder == null || _isRecording) return;

    try {
      await _recorder!.startRecorder(
        toFile: 'audio.aac', // âœ… íŒŒì¼ì— ì €ì¥
        codec: Codec.aacADTS,
      );

      _isRecording = true;
      notifyListeners();
    } catch (e) {
      debugPrint('ë…¹ìŒ ì‹œì‘ ì˜¤ë¥˜: $e');
    }
  }

  Future<void> stopRecording() async {
    if (_recorder == null || !_isRecording) return;

    try {
      final path = await _recorder!.stopRecorder();
      _isRecording = false;
      notifyListeners();

      if (path != null && onAudioData != null) {
        final fileData = await _readFileAsBytes(path);
        final encoded = base64Encode(fileData);
        onAudioData!(encoded);
      }
    } catch (e) {
      debugPrint('ë…¹ìŒ ì¤‘ì§€ ì˜¤ë¥˜: $e');
    }
  }

  Future<Uint8List> _readFileAsBytes(String path) async {
    final file = File(path);
    return await file.readAsBytes();
  }

  Future<void> playAudioData(String encodedData) async {
    if (_player == null) return;

    try {
      Uint8List audioData = base64Decode(encodedData);
      await _player!.startPlayer(
        fromDataBuffer: audioData,
        codec: Codec.pcm16,
        sampleRate: 16000,
        numChannels: 1,
      );
    } catch (e) {
      debugPrint('ì˜¤ë””ì˜¤ ì¬ìƒ ì˜¤ë¥˜: $e');
    }
  }

  // âœ… ì—¬ê¸° ì¶”ê°€!
  Future<void> transcribeAudio(String encodedData) async {
    try {
      Uint8List audioData = base64Decode(encodedData);
      final file = File(
        '/tmp/audio.wav',
      ); // ì„ì‹œ ì €ì¥ ê²½ë¡œ (iOS/AndroidëŠ” ë‹¤ë¥¸ ê²½ë¡œ ì¨ì•¼ í•  ìˆ˜ë„ ìˆìŒ)
      await file.writeAsBytes(audioData);

      final request = http.MultipartRequest(
        'POST',
        Uri.parse('https://your-stt-server.com/api/transcribe'),
      );
      request.files.add(await http.MultipartFile.fromPath('file', file.path));

      final response = await request.send();
      final responseBody = await response.stream.bytesToString();

      if (response.statusCode == 200) {
        final result = jsonDecode(responseBody);
        final transcript = result['text'] ?? 'STT ì‹¤íŒ¨';
        debugPrint('ğŸ™ï¸ STT ê²°ê³¼: $transcript');

        if (onAudioData != null) {
          onAudioData!(transcript);
        }
      } else {
        debugPrint('STT ìš”ì²­ ì‹¤íŒ¨: ${response.statusCode}');
      }
    } catch (e) {
      debugPrint('STT ì²˜ë¦¬ ì˜¤ë¥˜: $e');
    }
  }

  @override
  void dispose() {
    _recorder?.closeRecorder();
    _player?.closePlayer();

    super.dispose();
  }
}
